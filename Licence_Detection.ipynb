{"cells":[{"cell_type":"markdown","metadata":{"id":"3HbsXwbTKdu9"},"source":["### 0. checking access for GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axARdsB1KUR0","outputId":"d836f93d-2964-4379-c117-51a5f766b8cb","executionInfo":{"status":"ok","timestamp":1693813988522,"user_tz":-180,"elapsed":6,"user":{"displayName":"Khaled Tarek","userId":"13908474901056228319"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Sep  4 07:53:08 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   60C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6sVDhHJBiyz","executionInfo":{"status":"ok","timestamp":1694445665375,"user_tz":-180,"elapsed":19696,"user":{"displayName":"Khaled Tarek","userId":"13908474901056228319"}},"outputId":"c33a5f32-f63f-467b-8fbe-c29b65159187"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxEnaodhBfJ0","executionInfo":{"status":"ok","timestamp":1694432215904,"user_tz":-180,"elapsed":411,"user":{"displayName":"Khaled Tarek","userId":"13908474901056228319"}},"outputId":"40da7354-05d5-4a2b-cd83-f017ca562f9c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z3Irm0-4K0vF","outputId":"a32cdc48-2ac6-4a01-bc2c-8c9d727c06b6","executionInfo":{"status":"ok","timestamp":1694432217439,"user_tz":-180,"elapsed":2,"user":{"displayName":"Khaled Tarek","userId":"13908474901056228319"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition\n"]}],"source":["# Check Dir Root\n","import os\n","Home = os.getcwd()\n","print(Home)"]},{"cell_type":"markdown","metadata":{"id":"JIiUT-EvHbF1"},"source":["### 1. Install YOLOv8 from pip"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"vXjzgAzAF6r2","executionInfo":{"status":"ok","timestamp":1694432233623,"user_tz":-180,"elapsed":6836,"user":{"displayName":"Khaled Tarek","userId":"13908474901056228319"}}},"outputs":[],"source":["!pip install ultralytics\n","\n","from IPython import display\n","display.clear_output()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XrGC0qaIHyXI","outputId":"6c5e8878-9003-4a4e-81f9-e53b5e828010","executionInfo":{"status":"ok","timestamp":1694432238537,"user_tz":-180,"elapsed":4919,"user":{"displayName":"Khaled Tarek","userId":"13908474901056228319"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.175 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.2/78.2 GB disk)\n"]}],"source":["# Check ultralystics\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"markdown","metadata":{"id":"06i8daV1nFsv"},"source":["### 3. Getting custom Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ISjvOArfnY2n","executionInfo":{"status":"ok","timestamp":1694432259937,"user_tz":-180,"elapsed":18640,"user":{"displayName":"Khaled Tarek","userId":"13908474901056228319"}}},"outputs":[],"source":["!pip install roboflow\n","display.clear_output()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QhhKc8anr-4","outputId":"95d0fbca-912f-435d-c621-31ee6055023a","executionInfo":{"status":"ok","timestamp":1694432267923,"user_tz":-180,"elapsed":403,"user":{"displayName":"Khaled Tarek","userId":"13908474901056228319"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition/DataSets\n"]}],"source":["!mkdir {Home}/DataSets\n","%cd {Home}/DataSets"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSoUOtkNl9Ln","outputId":"ff5b48c5-b60c-4b8b-8083-9cbc0208157a","executionInfo":{"status":"ok","timestamp":1694432871120,"user_tz":-180,"elapsed":593574,"user":{"displayName":"Khaled Tarek","userId":"13908474901056228319"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Dependency ultralytics==8.0.134 is required but found version=8.0.175, to fix: `pip install ultralytics==8.0.134`\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in License-Plate-Recognition-4 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 974784/974784 [01:26<00:00, 11222.33it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to License-Plate-Recognition-4 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48488/48488 [08:21<00:00, 96.75it/s] \n"]}],"source":["from roboflow import Roboflow\n","rf = Roboflow(api_key=\"3xqoQhgk2T2SnBmvFHiE\")\n","project = rf.workspace(\"roboflow-universe-projects\").project(\"license-plate-recognition-rxg4e\")\n","dataset = project.version(4).download(\"yolov8\")"]},{"cell_type":"markdown","metadata":{"id":"x6AIV6FDobWB"},"source":["### 4. Custom Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nlNjbmKMnQnq","outputId":"c5ae8ff3-8691-4126-f624-5f7d7d550e5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition\n"]},{"output_type":"stream","name":"stderr","text":["Ultralytics YOLOv8.0.175 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=/content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition/DataSets/License-Plate-Recognition-4/data.yaml, epochs=25, patience=50, batch=16, imgsz=600, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train2\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 24.2MB/s]\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776275  ultralytics.nn.modules.head.Detect           [1, [192, 384, 576]]          \n","Model summary: 295 layers, 25856899 parameters, 25856883 gradients\n","\n","Transferred 469/475 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 44.3MB/s]\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","WARNING âš ï¸ imgsz=[600] must be multiple of max stride 32, updating to [608]\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition/DataSets/License-Plate-Recognition-4/train/labels... 21173 images, 28 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21173/21173 [01:39<00:00, 213.29it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition/DataSets/License-Plate-Recognition-4/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition/DataSets/License-Plate-Recognition-4/valid/labels... 2046 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2046/2046 [00:11<00:00, 179.00it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition/DataSets/License-Plate-Recognition-4/valid/labels.cache\n","Plotting labels to runs/detect/train2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 608 train, 608 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2\u001b[0m\n","Starting training for 25 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/25      6.32G      1.333     0.9114      1.372         13        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [11:23<00:00,  1.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:34<00:00,  1.83it/s]\n","                   all       2046       2132      0.907      0.836      0.901      0.557\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/25      6.53G      1.308     0.8146      1.351         11        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [11:03<00:00,  1.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.95it/s]\n","                   all       2046       2132      0.964      0.887      0.947      0.578\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/25      6.58G      1.268     0.7653      1.325         10        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:56<00:00,  2.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.94it/s]\n","                   all       2046       2132      0.952      0.907      0.955       0.58\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/25      6.57G      1.221     0.7089      1.293         12        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [11:02<00:00,  2.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:33<00:00,  1.90it/s]\n","                   all       2046       2132      0.959      0.912      0.952      0.602\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/25       6.6G      1.208     0.6789      1.281          8        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [11:11<00:00,  1.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:33<00:00,  1.92it/s]\n","                   all       2046       2132      0.965      0.929      0.962      0.625\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/25      6.58G      1.178      0.646      1.266          8        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:57<00:00,  2.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.95it/s]\n","                   all       2046       2132      0.966      0.927      0.966      0.629\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/25      6.59G      1.159     0.6189      1.252          9        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:52<00:00,  2.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.97it/s]\n","                   all       2046       2132       0.96      0.944      0.971      0.657\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/25       6.6G      1.139     0.6033      1.237         11        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:53<00:00,  2.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.96it/s]\n","                   all       2046       2132      0.975      0.939      0.977      0.655\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/25       6.6G      1.133     0.5832      1.232         11        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:48<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.96it/s]\n","                   all       2046       2132      0.939       0.95      0.972      0.657\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/25      6.46G      1.124     0.5673      1.231         15        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:49<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.98it/s]\n","                   all       2046       2132      0.966      0.947      0.971       0.65\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/25       6.6G      1.108     0.5569      1.216         11        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:49<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.97it/s]\n","                   all       2046       2132      0.977      0.942      0.976      0.661\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/25       6.6G      1.093     0.5394      1.212          8        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:51<00:00,  2.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.97it/s]\n","                   all       2046       2132      0.965      0.958       0.98      0.673\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/25       6.6G      1.083     0.5274      1.203          8        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:48<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.97it/s]\n","                   all       2046       2132      0.972      0.952      0.979      0.662\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/25      6.61G       1.07     0.5142      1.194          8        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:46<00:00,  2.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:33<00:00,  1.89it/s]\n","                   all       2046       2132      0.974      0.959       0.98      0.669\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/25      6.59G      1.066     0.5054       1.19          7        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:56<00:00,  2.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.96it/s]\n","                   all       2046       2132      0.971      0.959      0.982      0.686\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/25       6.6G      1.049     0.4291      1.206          5        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:49<00:00,  2.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.98it/s]\n","                   all       2046       2132      0.973      0.963      0.984      0.697\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/25       6.6G      1.036     0.4164      1.197          5        608: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1324/1324 [10:41<00:00,  2.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:32<00:00,  1.99it/s]\n","                   all       2046       2132      0.968      0.971      0.985       0.69\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/25      6.57G      1.018     0.4019      1.193         16        608:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 720/1324 [05:48<04:50,  2.08it/s]"]}],"source":["%cd {Home}\n","from ultralytics import YOLO\n","# Load a model\n","model = YOLO('yolov8m.pt')  # load a pretrained model (recommended for training)\n","\n","data_path= '/content/drive/MyDrive/Object_Detection/Licence_Plate_Recognition/DataSets/License-Plate-Recognition-4/data.yaml'\n","# Train the model\n","result = model.train(data= data_path , epochs=25, imgsz=600,plots=True)"]},{"cell_type":"markdown","metadata":{"id":"0qQYfbkl-dVA"},"source":["### 5. Validate Custom Model"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"BprsJWkPp0wz","executionInfo":{"status":"ok","timestamp":1694445861282,"user_tz":-180,"elapsed":244,"user":{"displayName":"Khaled Tarek","userId":"13908474901056228319"}}},"outputs":[],"source":["# # Validate the model\n","# metrics = model.val()\n","# metrics.box.maps   # a list contains map50-95 of each category"]},{"cell_type":"markdown","metadata":{"id":"EGe1OYdRXu-D"},"source":["### 6. Model Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jmxNc8VJcIM_"},"outputs":[],"source":["# Train Result\n","import cv2\n","img =cv2.imread(\"/content/runs/detect/train2/results.png\")\n","cv2_imshow(cv2.resize(img, (1000, 600)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dEVJoYxoX5XD"},"outputs":[],"source":["# 1. Val Confusion Matrix\n","import cv2\n","img =cv2.imread(\"/content/runs/detect/val/confusion_matrix_normalized.png\")\n","cv2_imshow(cv2.resize(img, (800, 600)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KoTpgFA8ZwGV"},"outputs":[],"source":["# 2. Val Precision Curve\n","img = cv2.imread(\"/content/runs/detect/val/P_curve.png\")\n","cv2_imshow(cv2.resize(img,(800,600)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKadcj92bfKr"},"outputs":[],"source":["# 3. Val Recall Curve\n","img = cv2.imread(\"/content/runs/detect/val/R_curve.png\")\n","cv2_imshow(cv2.resize(img,(800,600)))"]},{"cell_type":"markdown","metadata":{"id":"ZMJvsvz1By7s"},"source":["### 6. Inference with Custom Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aYPzu7t9dPBi"},"outputs":[],"source":["results = model.predict(\"/content/DataSets/Match-2/test/images\", save=True, imgsz=320, conf=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQvZLg76-c9Y"},"outputs":[],"source":["# Showing Some predicting results\n","import glob\n","for image_path in glob.glob(f'{Home}/runs/detect/predict/*.jpg')[:3]:\n","      img = cv2.imread(image_path)\n","      cv2_imshow(cv2.resize(img,(400,400)))\n","      print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPXVOd2MeioV"},"outputs":[],"source":["img = cv2.imread(\"/content/images.jpeg\")\n","res = model.predict(img)\n","res_plotted = res[0].plot()\n","cv2_imshow(res_plotted)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y86ASdJ-iFZ4"},"outputs":[],"source":["import cv2\n","from ultralytics import YOLO\n","\n","# Load the YOLOv8 model\n","model = YOLO('yolov8n.pt')\n","\n","# Open the video file\n","video_path = \"/content/1.mp4\"\n","cap = cv2.VideoCapture(video_path)\n","\n","# Loop through the video frames\n","while cap.isOpened():\n","    # Read a frame from the video\n","    success, frame = cap.read()\n","\n","    if success:\n","        # Run YOLOv8 inference on the frame\n","        results = model(frame)\n","\n","        # Visualize the results on the frame\n","        annotated_frame = results[0].plot()\n","\n","        # Display the annotated frame\n","        cv2_imshow(nce\", annotated_frame)\n","\n","        # Break the loop if 'q' is pressed\n","        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n","            break\n","    else:\n","        # Break the loop if the end of the video is reached\n","        break\n","\n","# Release the video capture object and close the display window\n","cap.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"40gaoy5woOr4"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}